{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Kaggle Data\n",
    "\n",
    "file_dir = 'C:/Users/ruchi/Desktop/Berkley Extension Learning Docs/Final Project'\n",
    "\n",
    "kaggle_metadata = pd.read_csv(f'{file_dir}/US_Accidents_Dec19.tar.gz', compression='gzip', error_bad_lines=False, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Turn off SettingWithCopyWarning ##############\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2974336"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check total rows extraced\n",
    "len(kaggle_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only Columns relevant for analysis\n",
    "df_subset = kaggle_metadata[['US_Accidents_Dec19.csv','Severity','Start_Time','End_Time',\n",
    "                             'Start_Lat','Start_Lng','Distance(mi)', 'Street','Side','City',\n",
    "                             'County','State','Zipcode','Timezone', \n",
    "                             'Temperature(F)','Humidity(%)','Pressure(in)',\n",
    "                             'Visibility(mi)','Wind_Direction','Wind_Speed(mph)','Precipitation(in)',\n",
    "                             'Weather_Condition','Amenity','Crossing','Junction','Railway',\n",
    "                             'Station','Stop','Traffic_Signal','Civil_Twilight'\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US_Accidents_Dec19.csv          1\n",
       "Severity                        1\n",
       "Start_Time                      1\n",
       "End_Time                        1\n",
       "Start_Lat                       1\n",
       "Start_Lng                       1\n",
       "Distance(mi)                    1\n",
       "Street                          1\n",
       "Side                            1\n",
       "City                           84\n",
       "County                          1\n",
       "State                           1\n",
       "Zipcode                       881\n",
       "Timezone                     3164\n",
       "Temperature(F)              56064\n",
       "Humidity(%)                 59174\n",
       "Pressure(in)                48143\n",
       "Visibility(mi)              65692\n",
       "Wind_Direction              45102\n",
       "Wind_Speed(mph)            440841\n",
       "Precipitation(in)         1998359\n",
       "Weather_Condition           65933\n",
       "Amenity                         1\n",
       "Crossing                        1\n",
       "Junction                        1\n",
       "Railway                         1\n",
       "Station                         1\n",
       "Stop                            1\n",
       "Traffic_Signal                  1\n",
       "Civil_Twilight                 94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Null Values\n",
    "df_subset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with zero values for Precipitation column\n",
    "df_subset[\"Precipitation(in)\"].fillna(0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with other NA values\n",
    "df_subset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506618"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the resulting dataset length\n",
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe on Severity so that when removing duplicates the one with higher severity is retained\n",
    "sorted_df = df_subset.sort_values('Severity',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2494218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many duplicates exist in the dataset\n",
    "len(sorted_df[['Severity', 'Start_Time', 'Start_Lat', 'Start_Lng']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "sorted_df.drop_duplicates(subset=['Severity', 'Start_Time', 'Start_Lat', 'Start_Lng'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first 5 digits of zipcode where zip code is in postal format of ZIP-4\n",
    "sorted_df['Zipcode'] = sorted_df['Zipcode'].str.replace(r\"-.*\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2494218"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length of the remaining dataset after removing duplicate and Null value rows\n",
    "len(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US_Accidents_Dec19.csv     object\n",
       "Severity                  float64\n",
       "Start_Time                 object\n",
       "End_Time                   object\n",
       "Start_Lat                 float64\n",
       "Start_Lng                 float64\n",
       "Distance(mi)              float64\n",
       "Street                     object\n",
       "Side                       object\n",
       "City                       object\n",
       "County                     object\n",
       "State                      object\n",
       "Zipcode                    object\n",
       "Timezone                   object\n",
       "Temperature(F)            float64\n",
       "Humidity(%)               float64\n",
       "Pressure(in)              float64\n",
       "Visibility(mi)            float64\n",
       "Wind_Direction             object\n",
       "Wind_Speed(mph)           float64\n",
       "Precipitation(in)         float64\n",
       "Weather_Condition          object\n",
       "Amenity                    object\n",
       "Crossing                   object\n",
       "Junction                   object\n",
       "Railway                    object\n",
       "Station                    object\n",
       "Stop                       object\n",
       "Traffic_Signal             object\n",
       "Civil_Twilight             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes for corrections\n",
    "sorted_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['Start_Time'] = pd.to_datetime(sorted_df.Start_Time)\n",
    "sorted_df['End_Time'] = pd.to_datetime(sorted_df.End_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################   Create Highway Column   ####################################\n",
    "\n",
    "\n",
    "searchfor = ['highway', 'Tollway', 'expy', 'fwy', 'hwy', 'Interstate', \n",
    "             'Tpke', 'Pkwy', 'Parkway', '-', 'US', 'Route', \n",
    "             'FM', 'Byp', 'Trwy', 'Beltway', 'Skyway', 'Skwy', ]\n",
    "sorted_df.loc[sorted_df['Street'].str.contains('|'.join(searchfor), case=False), 'Highway'] = 'Y'\n",
    "\n",
    "# Fill NA with zero values for Precipitation column\n",
    "sorted_df[\"Highway\"].fillna('N', inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2584250</th>\n",
       "      <td>48.964400</td>\n",
       "      <td>-122.441456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455305</th>\n",
       "      <td>47.701420</td>\n",
       "      <td>-122.344660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888675</th>\n",
       "      <td>42.552910</td>\n",
       "      <td>-84.797750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888674</th>\n",
       "      <td>42.552100</td>\n",
       "      <td>-84.789336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455314</th>\n",
       "      <td>36.734570</td>\n",
       "      <td>-120.199785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283448</th>\n",
       "      <td>29.735319</td>\n",
       "      <td>-95.460625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140799</th>\n",
       "      <td>27.878984</td>\n",
       "      <td>-82.658920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679691</th>\n",
       "      <td>32.667721</td>\n",
       "      <td>-97.204468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970482</th>\n",
       "      <td>33.480442</td>\n",
       "      <td>-111.889946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429943</th>\n",
       "      <td>34.944920</td>\n",
       "      <td>-80.779366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Start_Lat   Start_Lng\n",
       "2584250  48.964400 -122.441456\n",
       "2455305  47.701420 -122.344660\n",
       "2888675  42.552910  -84.797750\n",
       "2888674  42.552100  -84.789336\n",
       "2455314  36.734570 -120.199785\n",
       "...            ...         ...\n",
       "283448   29.735319  -95.460625\n",
       "140799   27.878984  -82.658920\n",
       "679691   32.667721  -97.204468\n",
       "1970482  33.480442 -111.889946\n",
       "1429943  34.944920  -80.779366\n",
       "\n",
       "[1190354 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df[['Start_Lat','Start_Lng']][sorted_df['Highway'] == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Coordinates column\n",
    "sorted_df['Coordinates'] = sorted_df['Start_Lat'].map(str) + ', ' + sorted_df['Start_Lng'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and reset index\n",
    "sorted_df = sorted_df.rename(index=str,columns={'US_Accidents_Dec19.csv': 'Accident_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframes for Loading into SQL Tables \n",
    "\n",
    "table1_df = sorted_df[['Accident_ID','Severity','Start_Time','End_Time',\n",
    "                             'Start_Lat','Start_Lng','Coordinates', 'Distance(mi)', 'Side', \n",
    "                             'Temperature(F)','Humidity(%)','Pressure(in)',\n",
    "                             'Visibility(mi)','Wind_Direction','Wind_Speed(mph)','Precipitation(in)',\n",
    "                             'Weather_Condition','Amenity','Crossing','Junction','Railway',\n",
    "                             'Station','Stop','Traffic_Signal','Civil_Twilight'\n",
    "                             ]]\n",
    "table2_df = sorted_df[['Coordinates', 'Street','City','County','State','Zipcode',\n",
    "                       'Timezone', 'Highway']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Index\n",
    "table1_df.set_index('Accident_ID', inplace=True)\n",
    "table2_df.set_index('Coordinates', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2_df.dtypes.to_csv('tab2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Date and Time Column into Date, Time, Time in Seconds, and Day of week columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value Start date time column\n",
    "newstart = sorted_df[\"Start_Time\"].str.split(\" \",expand = True) \n",
    "  \n",
    "# making separate Start Time column from new data frame \n",
    "sorted_df[\"Start_Time_of_Day\"]= newstart[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value End date time column\n",
    "newend = sorted_df[\"End_Time\"].str.split(\" \",expand = True) \n",
    "\n",
    "# making separate Start Time column from new data frame \n",
    "sorted_df[\"End_Time_of_Day\"]= newend[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Time to seconds for Start Time and End Time\n",
    "sorted_df['Start_seconds'] = pd.to_timedelta(sorted_df['Start_Time_of_Day']).dt.seconds\n",
    "\n",
    "# Convert Time to seconds for Start Time and End Time\n",
    "sorted_df['End_seconds'] = pd.to_timedelta(sorted_df['End_Time_of_Day']).dt.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['Start_Time'] = pd.to_datetime(sorted_df.Start_Time)\n",
    "sorted_df['End_Time'] = pd.to_datetime(sorted_df.End_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Day of the week for the accident\n",
    "sorted_df['Day_of_Week'] = sorted_df['Start_Time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df[sorted_df['US_Accidents_Dec19.csv'] == 'A-2782717']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.head(100).to_csv('Sample_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
